{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "|<h2>Course:</h2>|<h1><a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">A deep understanding of AI language model mechanisms</a></h1>|\n",
        "|-|:-:|\n",
        "|<h2>Part 1:</h2>|<h1>Tokenizations and embeddings<h1>|\n",
        "|<h2>Section:</h2>|<h1>Words to tokens to numbers<h1>|\n",
        "|<h2>Lecture:</h2>|<h1><b>Parsing text to numbered tokens<b></h1>|\n",
        "\n",
        "<br>\n",
        "\n",
        "<h5><b>Teacher:</b> Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h5>\n",
        "<h5><b>Course URL:</b> <a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">udemy.com/course/dullms_x/?couponCode=202508</a></h5>\n",
        "<i>Using the code without the course may lead to confusion or errors.</i>"
      ],
      "metadata": {
        "id": "dBsNRoJ8HpGk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KDVo9UpRHuaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parsing text into words"
      ],
      "metadata": {
        "id": "mcl6mvSJ0z6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the text\n",
        "text = [ 'All that we are is the result of what we have thought',\n",
        "         'To be or not to be that is the question',\n",
        "         'Be yourself everyone else is already taken' ]\n",
        "\n",
        "text"
      ],
      "metadata": {
        "id": "RmFWYsyFHuXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# separate into words by splitting by spaces\n",
        "import re\n",
        "re.split('\\s',text[0])"
      ],
      "metadata": {
        "id": "83q3ZHR6HuSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# can recombine into a text\n",
        "' '.join( re.split('\\s',text[0]) )"
      ],
      "metadata": {
        "id": "F3xIl0TZHuPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# also make lower-case\n",
        "allwords = re.split('\\s',' '.join(text).lower())\n",
        "allwords"
      ],
      "metadata": {
        "id": "5jMgUhoFJFCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xWjXaGF40-Y2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a vocabulary (lexicon)"
      ],
      "metadata": {
        "id": "p3vIFNqe0-V7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# find the unique words\n",
        "vocab = sorted(set(allwords))\n",
        "vocab"
      ],
      "metadata": {
        "id": "Xt6qDnGvHuNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'There are {len(allwords)} words in the text, and {len(vocab)} words in the vocabulary')"
      ],
      "metadata": {
        "id": "bJIoqHSLHuHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1LNdk--11DH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create an encoder and decoder"
      ],
      "metadata": {
        "id": "SQOK9BE31DDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the encoder is a python dictionary type\n",
        "word2idx = {}\n",
        "for i,word in enumerate(vocab):\n",
        "  word2idx[word] = i\n",
        "word2idx"
      ],
      "metadata": {
        "id": "RQk8dGyBHuEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# and a decoder\n",
        "idx2word = {}\n",
        "for i,word in enumerate(vocab):\n",
        "  idx2word[i] = word\n",
        "idx2word"
      ],
      "metadata": {
        "id": "PqKALTBaHuBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'The word \"to\" has index {word2idx[\"to\"]}')\n",
        "print(f'The index \"7\" maps to the word \"{idx2word[7]}\"')"
      ],
      "metadata": {
        "id": "NTR0BMxdHt-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P1VfwvVt1NUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make fake quotes, just for fun :P"
      ],
      "metadata": {
        "id": "GULhYnOP1NSA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# select random words from the dictionary\n",
        "import numpy as np\n",
        "randidx = np.random.randint(0,len(vocab),size=5)\n",
        "\n",
        "# words of wisdom as a list of tokens\n",
        "[ idx2word[i] for i in randidx ]"
      ],
      "metadata": {
        "id": "QGCwhK-GHt8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# does it sound more wise as text??\n",
        "' '.join([ idx2word[i] for i in randidx ])"
      ],
      "metadata": {
        "id": "d0QzTDjSUU-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0StRY37I1dwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A peek at tokenization"
      ],
      "metadata": {
        "id": "_X2k966q1dpW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# translate the text into numbers\n",
        "text_as_int = [ word2idx[word] for word in allwords ]\n",
        "text_as_int"
      ],
      "metadata": {
        "id": "rLBJ8ijaL5um"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# and numbers back into text\n",
        "for tokeni in text_as_int:\n",
        "  print(f'Token {tokeni:2}: {idx2word[tokeni]}')"
      ],
      "metadata": {
        "id": "D9VtmaEb15kX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "beWoY-qYOyLn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}